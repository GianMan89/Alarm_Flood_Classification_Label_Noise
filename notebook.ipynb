{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ec76f3",
   "metadata": {},
   "source": [
    "## Imports and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c502c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from classifiers.WDI_1NN import WDI_1NN\n",
    "from classifiers.ACM_SVM import ACM_SVM\n",
    "from classifiers.CASIM import CASIM\n",
    "from classifiers.EAC_1NN import EAC_1NN\n",
    "from classifiers.MBW_LR import MBW_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e2445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "N_REPEATS = 10\n",
    "N_SPLITS = 5\n",
    "MAX_DATA_LENGTH = 60\n",
    "PERTURBATION_STEP_SIZE = 0.10\n",
    "\n",
    "SAVE_DIR = \"results\"\n",
    "\n",
    "# Order of parameters: [params_dict, use_argmin, stepwise_train]\n",
    "wdi_1nn_params = [{\"template_threshold\": 0.5, \"n_neighbors\": 1}, False, True]\n",
    "acm_svm_params = [{None}, False, False]\n",
    "casim_params=[{\n",
    "        \"num_features\": 672,\n",
    "        \"n_estimators\": 1,\n",
    "        \"n_jobs_multirocket\": 1,\n",
    "        \"random_state\": RANDOM_SEED,\n",
    "        \"alphas\": np.logspace(-3, 3, 10),\n",
    "    }, False, True]\n",
    "eac_1nn_params = [{\"attenuation_coefficient_per_min\": 0.0667}, False, True]\n",
    "mbw_lr_params = [{\n",
    "        \"penalty\": None,\n",
    "        \"fit_intercept\": False,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"multi_class\": \"ovr\",\n",
    "        \"decision_bounds\": True,\n",
    "        \"confidence_interval\": 1.96,\n",
    "    }, False, True]\n",
    "\n",
    "CLASSIFIERS = {\n",
    "    \"WDI_1NN\": (WDI_1NN, wdi_1nn_params),\n",
    "    \"CASIM\": (CASIM, casim_params),\n",
    "    \"EAC_1NN\": (EAC_1NN, eac_1nn_params),\n",
    "    \"MBW_LR\": (MBW_LR, mbw_lr_params),\n",
    "    \"ACM_SVM\": (ACM_SVM, acm_svm_params),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec45514",
   "metadata": {},
   "source": [
    "## Load Data and Original Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeea7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_folder(base_path, max_data_length):\n",
    "    \"\"\"\n",
    "    Load time-series CSV files organized in subfolders per class.\n",
    "\n",
    "    Parameters\n",
    "    - base_path: str or Path to the folder containing one subfolder per class.\n",
    "                 Each class subfolder should contain CSV files (all same shape).\n",
    "    - max_data_length: int, maximum length of the time series data (number of timesteps).\n",
    "\n",
    "    Returns\n",
    "    - X: numpy array of shape (n_samples, n_variables, n_timesteps)\n",
    "    - y: numpy array of integer labels (0..n_classes-1)\n",
    "\n",
    "    Prints shapes of X and y.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # Find subfolders (classes) in deterministic order\n",
    "    class_folders = sorted(\n",
    "        [\n",
    "            d for d in os.listdir(base_path)\n",
    "            if os.path.isdir(os.path.join(base_path, d))\n",
    "        ]\n",
    "    )\n",
    "    if not class_folders:\n",
    "        raise ValueError(f\"No class subfolders found in {base_path}\")\n",
    "\n",
    "    # Build list of files to load (with labels) to show a single progress bar\n",
    "    files_to_load = []\n",
    "    for label, class_name in enumerate(class_folders):\n",
    "        class_dir = os.path.join(base_path, class_name)\n",
    "        # Collect CSV files in deterministic order\n",
    "        csv_files = sorted(\n",
    "            [\n",
    "                f for f in os.listdir(class_dir)\n",
    "                if os.path.isfile(os.path.join(class_dir, f)) and f.lower().endswith(\".csv\")\n",
    "            ]\n",
    "        )\n",
    "        if not csv_files:\n",
    "            raise ValueError(f\"No CSV files found in class folder {class_dir}\")\n",
    "\n",
    "        for fname in csv_files:\n",
    "            files_to_load.append((os.path.join(class_dir, fname), label))\n",
    "\n",
    "    # Iterate with tqdm progress bar\n",
    "    for csv_path, label in tqdm(files_to_load, desc=\"Loading dataset\", unit=\"file\"):\n",
    "        df = pd.read_csv(csv_path, index_col=0)\n",
    "        arr = df.values.T  # transpose to match original layout: (variables, timesteps)\n",
    "        data.append(arr)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Ensure all samples have the same shape\n",
    "    shapes = {a.shape for a in data}\n",
    "    if len(shapes) != 1:\n",
    "        raise ValueError(f\"Inconsistent sample shapes found: {shapes}\")\n",
    "\n",
    "    X = np.array(data)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Resize data to max_data_length if necessary\n",
    "    if X.shape[2] > max_data_length:\n",
    "        X = X[:, :, :max_data_length]\n",
    "\n",
    "    print(\"Data shape: {}\".format(X.shape))\n",
    "    print(\"Labels shape: {}\".format(y.shape))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a916b",
   "metadata": {},
   "source": [
    "## Label Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb504092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelPerturber:\n",
    "    \"\"\"Class to handle label perturbation operations\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=None):\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def perturb_labels(self, y, perturbation_level, perturbation_step_size=0.1):\n",
    "        \"\"\"\n",
    "        Perturb labels by randomly changing a percentage of them to other classes.\n",
    "        \n",
    "        Parameters:\n",
    "        - y: array of labels\n",
    "        - perturbation_level: integer step level (0 = no perturbation)\n",
    "        - perturbation_step_size: percentage per step (e.g., 0.1 = 10% per step)\n",
    "        \n",
    "        Returns:\n",
    "        - perturbed labels array\n",
    "        \"\"\"\n",
    "        if perturbation_level == 0:\n",
    "            return y.copy()\n",
    "            \n",
    "        np.random.seed(self.random_state)\n",
    "        y_perturbed = y.copy()\n",
    "        unique_classes = np.unique(y)\n",
    "        num_samples = len(y)\n",
    "        num_perturb = int(num_samples * perturbation_step_size * perturbation_level)\n",
    "        \n",
    "        if num_perturb == 0:\n",
    "            return y_perturbed\n",
    "            \n",
    "        perturbed_indices = np.random.choice(num_samples, size=num_perturb, replace=False)\n",
    "        \n",
    "        for index in perturbed_indices:\n",
    "            original_label = y[index]\n",
    "            possible_perturbations = [cls for cls in unique_classes if cls != original_label]\n",
    "            new_label = np.random.choice(possible_perturbations)\n",
    "            y_perturbed[index] = new_label\n",
    "            \n",
    "        return y_perturbed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ecdf88",
   "metadata": {},
   "source": [
    "## Robustness Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a1e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustnessTester:\n",
    "    \"\"\"Class to test model robustness against label perturbations\"\"\"\n",
    "    \n",
    "    def __init__(self, classifiers_dict, perturber, n_splits=5, perturbation_step_size=0.1, \n",
    "                 random_state=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - classifiers_dict: dictionary with classifier info {name: (class, params)}\n",
    "        - perturber: LabelPerturber instance\n",
    "        - n_splits: number of CV folds\n",
    "        - perturbation_step_size: percentage per perturbation step\n",
    "        - random_state: random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.classifiers_dict = classifiers_dict\n",
    "        self.perturber = perturber\n",
    "        self.n_splits = n_splits\n",
    "        self.perturbation_step_size = perturbation_step_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def test_robustness(self, X, y, classifier_name, perturbation_steps=10):\n",
    "        \"\"\"\n",
    "        Test robustness of a specific classifier against label perturbation.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: feature data\n",
    "        - y: labels\n",
    "        - classifier_name: name of classifier to test (key in classifiers_dict)\n",
    "        - perturbation_steps: maximum perturbation level to test\n",
    "        \n",
    "        Returns:\n",
    "        - results DataFrame with accuracy for each fold and perturbation level\n",
    "        - confusion_matrices DataFrame with aggregated confusion matrices\n",
    "        \"\"\"\n",
    "        if classifier_name not in self.classifiers_dict:\n",
    "            raise ValueError(f\"Classifier '{classifier_name}' not found in classifiers_dict\")\n",
    "            \n",
    "        classifier_class, classifier_params = self.classifiers_dict[classifier_name]\n",
    "        params_dict = classifier_params[0]\n",
    "        \n",
    "        np.random.seed(self.random_state)\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        fold_results = []\n",
    "        confusion_matrices = []\n",
    "        \n",
    "        for step in range(0, perturbation_steps + 1):\n",
    "            step_confusion_matrix = None\n",
    "            \n",
    "            for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "                print(f\"Testing {classifier_name} - Fold {fold + 1}, Perturbation step {step}...\")\n",
    "                \n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                \n",
    "                # Perturb training labels\n",
    "                y_train_perturbed = self.perturber.perturb_labels(\n",
    "                    y_train, step, self.perturbation_step_size\n",
    "                )\n",
    "                \n",
    "                # Train model on perturbed data\n",
    "                model_instance = classifier_class(params_dict)\n",
    "                model_instance.fit(X_train, y_train_perturbed)\n",
    "                \n",
    "                # Evaluate on unperturbed test data\n",
    "                y_pred = model_instance.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                fold_results.append({\n",
    "                    'classifier': classifier_name,\n",
    "                    'fold': fold,\n",
    "                    'perturbation_percentage': round(self.perturbation_step_size * step * 100),\n",
    "                    'accuracy': accuracy\n",
    "                })\n",
    "                \n",
    "                # Accumulate confusion matrix\n",
    "                cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "                if step_confusion_matrix is None:\n",
    "                    step_confusion_matrix = cm\n",
    "                else:\n",
    "                    step_confusion_matrix += cm\n",
    "            \n",
    "            # Store aggregated confusion matrix for this perturbation level\n",
    "            cm_flat = step_confusion_matrix.flatten()\n",
    "            cm_dict = {f'cm_{i}_{j}': cm_flat[i * len(np.unique(y)) + j] \n",
    "                      for i in range(len(np.unique(y))) \n",
    "                      for j in range(len(np.unique(y)))}\n",
    "            cm_dict['classifier'] = classifier_name\n",
    "            cm_dict['perturbation_percentage'] = round(self.perturbation_step_size * step * 100)\n",
    "            confusion_matrices.append(cm_dict)\n",
    "        \n",
    "        # Process results\n",
    "        results_df = pd.DataFrame(fold_results)\n",
    "        results_pivot = results_df.pivot_table(\n",
    "            index='perturbation_percentage', \n",
    "            columns='fold', \n",
    "            values='accuracy'\n",
    "        )\n",
    "        results_pivot['average'] = results_pivot.mean(axis=1)\n",
    "        \n",
    "        cm_df = pd.DataFrame(confusion_matrices).set_index('perturbation_percentage')\n",
    "        \n",
    "        return results_pivot, cm_df\n",
    "    \n",
    "    def test_all_classifiers(self, X, y, perturbation_steps=10, save_results=True):\n",
    "        \"\"\"\n",
    "        Test robustness of all classifiers in the dictionary.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: feature data\n",
    "        - y: labels  \n",
    "        - perturbation_steps: maximum perturbation level to test\n",
    "        - save_results: whether to save results to CSV files\n",
    "        \n",
    "        Returns:\n",
    "        - Dictionary with results for each classifier\n",
    "        \"\"\"\n",
    "        all_results = {}\n",
    "        \n",
    "        for classifier_name in self.classifiers_dict.keys():\n",
    "            print(f\"\\nTesting robustness of {classifier_name}...\")\n",
    "            \n",
    "            results, cm = self.test_robustness(X, y, classifier_name, perturbation_steps)\n",
    "            all_results[classifier_name] = {'results': results, 'confusion_matrices': cm}\n",
    "            \n",
    "            if save_results:\n",
    "                os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "                results.to_csv(f\"{SAVE_DIR}/{classifier_name}_robustness_results.csv\")\n",
    "                cm.to_csv(f\"{SAVE_DIR}/{classifier_name}_confusion_matrices.csv\")\n",
    "        \n",
    "        return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbdce32",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7df18e",
   "metadata": {},
   "source": [
    "### Tennessee-Eastman Process (TEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f94d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1000/1000 [00:01<00:00, 547.22file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1000, 50, 60)\n",
      "Labels shape: (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset_from_folder(\"data/tep\", MAX_DATA_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2dd2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing robustness of WDI_1NN...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 0...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 0...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 0...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 0...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 0...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 1...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 1...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 1...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 1...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 1...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 2...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 2...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 2...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 2...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 2...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 3...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 3...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 3...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 3...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 3...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 4...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 4...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 4...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 4...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 4...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 5...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 5...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 5...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 5...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 5...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 6...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 6...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 6...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 6...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 6...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 7...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 7...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 7...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 7...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 7...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 8...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 8...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 8...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 8...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 8...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 9...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 9...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 9...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 9...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 9...\n",
      "Testing WDI_1NN - Fold 1, Perturbation step 10...\n",
      "Testing WDI_1NN - Fold 2, Perturbation step 10...\n",
      "Testing WDI_1NN - Fold 3, Perturbation step 10...\n",
      "Testing WDI_1NN - Fold 4, Perturbation step 10...\n",
      "Testing WDI_1NN - Fold 5, Perturbation step 10...\n",
      "\n",
      "Testing robustness of CASIM...\n",
      "Testing CASIM - Fold 1, Perturbation step 0...\n",
      "Testing CASIM - Fold 2, Perturbation step 0...\n",
      "Testing CASIM - Fold 3, Perturbation step 0...\n",
      "Testing CASIM - Fold 4, Perturbation step 0...\n",
      "Testing CASIM - Fold 5, Perturbation step 0...\n",
      "Testing CASIM - Fold 1, Perturbation step 1...\n",
      "Testing CASIM - Fold 2, Perturbation step 1...\n",
      "Testing CASIM - Fold 3, Perturbation step 1...\n",
      "Testing CASIM - Fold 4, Perturbation step 1...\n",
      "Testing CASIM - Fold 5, Perturbation step 1...\n",
      "Testing CASIM - Fold 1, Perturbation step 2...\n",
      "Testing CASIM - Fold 2, Perturbation step 2...\n",
      "Testing CASIM - Fold 3, Perturbation step 2...\n",
      "Testing CASIM - Fold 4, Perturbation step 2...\n",
      "Testing CASIM - Fold 5, Perturbation step 2...\n",
      "Testing CASIM - Fold 1, Perturbation step 3...\n",
      "Testing CASIM - Fold 2, Perturbation step 3...\n",
      "Testing CASIM - Fold 3, Perturbation step 3...\n",
      "Testing CASIM - Fold 4, Perturbation step 3...\n",
      "Testing CASIM - Fold 5, Perturbation step 3...\n",
      "Testing CASIM - Fold 1, Perturbation step 4...\n",
      "Testing CASIM - Fold 2, Perturbation step 4...\n",
      "Testing CASIM - Fold 3, Perturbation step 4...\n",
      "Testing CASIM - Fold 4, Perturbation step 4...\n",
      "Testing CASIM - Fold 5, Perturbation step 4...\n",
      "Testing CASIM - Fold 1, Perturbation step 5...\n",
      "Testing CASIM - Fold 2, Perturbation step 5...\n",
      "Testing CASIM - Fold 3, Perturbation step 5...\n",
      "Testing CASIM - Fold 4, Perturbation step 5...\n",
      "Testing CASIM - Fold 5, Perturbation step 5...\n",
      "Testing CASIM - Fold 1, Perturbation step 6...\n",
      "Testing CASIM - Fold 2, Perturbation step 6...\n",
      "Testing CASIM - Fold 3, Perturbation step 6...\n",
      "Testing CASIM - Fold 4, Perturbation step 6...\n",
      "Testing CASIM - Fold 5, Perturbation step 6...\n",
      "Testing CASIM - Fold 1, Perturbation step 7...\n",
      "Testing CASIM - Fold 2, Perturbation step 7...\n",
      "Testing CASIM - Fold 3, Perturbation step 7...\n",
      "Testing CASIM - Fold 4, Perturbation step 7...\n",
      "Testing CASIM - Fold 5, Perturbation step 7...\n",
      "Testing CASIM - Fold 1, Perturbation step 8...\n",
      "Testing CASIM - Fold 2, Perturbation step 8...\n",
      "Testing CASIM - Fold 3, Perturbation step 8...\n",
      "Testing CASIM - Fold 4, Perturbation step 8...\n",
      "Testing CASIM - Fold 5, Perturbation step 8...\n",
      "Testing CASIM - Fold 1, Perturbation step 9...\n",
      "Testing CASIM - Fold 2, Perturbation step 9...\n",
      "Testing CASIM - Fold 3, Perturbation step 9...\n",
      "Testing CASIM - Fold 4, Perturbation step 9...\n",
      "Testing CASIM - Fold 5, Perturbation step 9...\n",
      "Testing CASIM - Fold 1, Perturbation step 10...\n",
      "Testing CASIM - Fold 2, Perturbation step 10...\n",
      "Testing CASIM - Fold 3, Perturbation step 10...\n",
      "Testing CASIM - Fold 4, Perturbation step 10...\n",
      "Testing CASIM - Fold 5, Perturbation step 10...\n",
      "\n",
      "Testing robustness of EAC_1NN...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 0...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 0...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 0...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 0...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 0...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 1...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 1...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 1...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 1...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 1...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 2...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 2...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 2...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 2...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 2...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 3...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 3...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 3...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 3...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 3...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 4...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 4...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 4...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 4...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 4...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 5...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 5...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 5...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 5...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 5...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 6...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 6...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 6...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 6...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 6...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 7...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 7...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 7...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 7...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 7...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 8...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 8...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 8...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 8...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 8...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 9...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 9...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 9...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 9...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 9...\n",
      "Testing EAC_1NN - Fold 1, Perturbation step 10...\n",
      "Testing EAC_1NN - Fold 2, Perturbation step 10...\n",
      "Testing EAC_1NN - Fold 3, Perturbation step 10...\n",
      "Testing EAC_1NN - Fold 4, Perturbation step 10...\n",
      "Testing EAC_1NN - Fold 5, Perturbation step 10...\n",
      "\n",
      "Testing robustness of MBW_LR...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 0...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 0...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 0...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 0...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 0...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 1...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 1...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 1...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 1...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 1...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 2...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 2...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 2...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 2...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 2...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 3...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 3...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 3...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 3...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 3...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 4...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 4...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 4...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 4...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 4...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 5...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 5...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 5...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 5...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 5...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 6...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 6...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 6...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 6...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 6...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 7...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 7...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 7...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 7...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 7...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 8...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 8...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 8...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 8...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 8...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 9...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 9...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 9...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 9...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 9...\n",
      "Testing MBW_LR - Fold 1, Perturbation step 10...\n",
      "Testing MBW_LR - Fold 2, Perturbation step 10...\n",
      "Testing MBW_LR - Fold 3, Perturbation step 10...\n",
      "Testing MBW_LR - Fold 4, Perturbation step 10...\n",
      "Testing MBW_LR - Fold 5, Perturbation step 10...\n",
      "\n",
      "Testing robustness of ACM_SVM...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 0...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 0...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 0...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 0...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 0...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 1...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 1...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 1...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 1...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 1...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 2...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 2...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 2...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 2...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 2...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 3...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 3...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 3...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 3...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 3...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 4...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 4...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 4...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 4...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 4...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 5...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 5...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 5...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 5...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 5...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 6...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 6...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 6...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 6...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 6...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 7...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 7...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 7...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 7...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 7...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 8...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 8...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 8...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 8...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 8...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 9...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 9...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 9...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 9...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 9...\n",
      "Testing ACM_SVM - Fold 1, Perturbation step 10...\n",
      "Testing ACM_SVM - Fold 2, Perturbation step 10...\n",
      "Testing ACM_SVM - Fold 3, Perturbation step 10...\n",
      "Testing ACM_SVM - Fold 4, Perturbation step 10...\n",
      "Testing ACM_SVM - Fold 5, Perturbation step 10...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WDI_1NN': {'results': fold                         0      1      2      3      4  average\n",
       "  perturbation_percentage                                            \n",
       "  0                        0.905  0.945  0.945  0.945  0.975    0.943\n",
       "  10                       0.925  0.950  0.955  0.935  0.980    0.949\n",
       "  20                       0.915  0.965  0.955  0.935  0.975    0.949\n",
       "  30                       0.920  0.960  0.955  0.940  0.975    0.950\n",
       "  40                       0.920  0.965  0.955  0.950  0.975    0.953\n",
       "  50                       0.930  0.950  0.955  0.930  0.975    0.948\n",
       "  60                       0.900  0.935  0.885  0.830  0.935    0.897\n",
       "  70                       0.675  0.695  0.710  0.690  0.700    0.694\n",
       "  80                       0.205  0.175  0.225  0.270  0.225    0.220\n",
       "  90                       0.020  0.020  0.030  0.010  0.020    0.020\n",
       "  100                      0.005  0.015  0.015  0.000  0.000    0.007,\n",
       "  'confusion_matrices':                          cm_0_0  cm_0_1  cm_0_2  cm_0_3  cm_0_4  cm_1_0  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           180       0      20       0       0       0   \n",
       "  10                          181       0      19       0       0       0   \n",
       "  20                          177       0      23       0       0       0   \n",
       "  30                          178       0      22       0       0       0   \n",
       "  40                          178       0      22       0       0       0   \n",
       "  50                          176       1      21       1       1       0   \n",
       "  60                          150       6      27       4      13       0   \n",
       "  70                           67       5      28      16      84       0   \n",
       "  80                           64      21       9      19      87       3   \n",
       "  90                           20     100       4      38      38      28   \n",
       "  100                           7     115       6      53      19      27   \n",
       "  \n",
       "                           cm_1_1  cm_1_2  cm_1_3  cm_1_4  ...  cm_3_1  cm_3_2  \\\n",
       "  perturbation_percentage                                  ...                   \n",
       "  0                           188       1      11       0  ...       0       0   \n",
       "  10                          197       0       3       0  ...       0       0   \n",
       "  20                          199       0       1       0  ...       0       0   \n",
       "  30                          200       0       0       0  ...       0       0   \n",
       "  40                          200       0       0       0  ...       0       0   \n",
       "  50                          200       0       0       0  ...       0       0   \n",
       "  60                          195       0       5       0  ...       0       0   \n",
       "  70                          135       2      63       0  ...       0       0   \n",
       "  80                           10     121      65       1  ...      16      61   \n",
       "  90                            0      46      12     114  ...       1       3   \n",
       "  100                           0     121      10      42  ...       0      36   \n",
       "  \n",
       "                           cm_3_3  cm_3_4  cm_4_0  cm_4_1  cm_4_2  cm_4_3  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           200       0       0      24       0       1   \n",
       "  10                          200       0       0      28       0       1   \n",
       "  20                          200       0       0      27       0       0   \n",
       "  30                          200       0       0      28       0       0   \n",
       "  40                          200       0       0      25       0       0   \n",
       "  50                          200       0       0      22       0       0   \n",
       "  60                          200       0       0      20       0       0   \n",
       "  70                          200       0       0      27       3       2   \n",
       "  80                           34      41      18      41      32       2   \n",
       "  90                            0     147      18     140      32      10   \n",
       "  100                           0      63      12     142      39       7   \n",
       "  \n",
       "                           cm_4_4  classifier  \n",
       "  perturbation_percentage                      \n",
       "  0                           175     WDI_1NN  \n",
       "  10                          171     WDI_1NN  \n",
       "  20                          173     WDI_1NN  \n",
       "  30                          172     WDI_1NN  \n",
       "  40                          175     WDI_1NN  \n",
       "  50                          178     WDI_1NN  \n",
       "  60                          180     WDI_1NN  \n",
       "  70                          168     WDI_1NN  \n",
       "  80                          107     WDI_1NN  \n",
       "  90                            0     WDI_1NN  \n",
       "  100                           0     WDI_1NN  \n",
       "  \n",
       "  [11 rows x 26 columns]},\n",
       " 'CASIM': {'results': fold                         0      1      2      3      4  average\n",
       "  perturbation_percentage                                            \n",
       "  0                        1.000  1.000  0.995  1.000  1.000    0.999\n",
       "  10                       1.000  0.995  0.990  0.990  0.995    0.994\n",
       "  20                       0.995  1.000  1.000  0.995  1.000    0.998\n",
       "  30                       0.965  0.990  0.995  0.965  0.990    0.981\n",
       "  40                       0.950  0.970  0.950  0.935  0.980    0.957\n",
       "  50                       0.805  0.830  0.855  0.860  0.830    0.836\n",
       "  60                       0.295  0.285  0.320  0.395  0.350    0.329\n",
       "  70                       0.310  0.225  0.310  0.220  0.310    0.275\n",
       "  80                       0.275  0.170  0.175  0.135  0.155    0.182\n",
       "  90                       0.145  0.090  0.160  0.280  0.160    0.167\n",
       "  100                      0.205  0.240  0.110  0.425  0.385    0.273,\n",
       "  'confusion_matrices':                          cm_0_0  cm_0_1  cm_0_2  cm_0_3  cm_0_4  cm_1_0  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           200       0       0       0       0       0   \n",
       "  10                          198       0       0       2       0       0   \n",
       "  20                          199       0       1       0       0       0   \n",
       "  30                          194       0       6       0       0       2   \n",
       "  40                          187       2       6       4       1       2   \n",
       "  50                          161       4      10       8      17      11   \n",
       "  60                            1      41      10      43     105      26   \n",
       "  70                           12      60       8      56      64       6   \n",
       "  80                            3      51       1     129      16      17   \n",
       "  90                           60      57       0      56      27      49   \n",
       "  100                         137       6       1      56       0      18   \n",
       "  \n",
       "                           cm_1_1  cm_1_2  cm_1_3  cm_1_4  ...  cm_3_1  cm_3_2  \\\n",
       "  perturbation_percentage                                  ...                   \n",
       "  0                           200       0       0       0  ...       0       0   \n",
       "  10                          199       0       1       0  ...       0       0   \n",
       "  20                          200       0       0       0  ...       0       0   \n",
       "  30                          191       0       5       2  ...       2       0   \n",
       "  40                          182       2       9       5  ...       6       0   \n",
       "  50                          124      23      18      24  ...       3       2   \n",
       "  60                          105       6      23      40  ...      12       1   \n",
       "  70                           72      15      34      73  ...      61       8   \n",
       "  80                           42       5     122      14  ...      56      16   \n",
       "  90                           99       3      12      37  ...      57       1   \n",
       "  100                          68      24      83       7  ...     131      16   \n",
       "  \n",
       "                           cm_3_3  cm_3_4  cm_4_0  cm_4_1  cm_4_2  cm_4_3  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           200       0       0       0       0       0   \n",
       "  10                          200       0       0       0       0       0   \n",
       "  20                          200       0       0       0       0       0   \n",
       "  30                          198       0       0       0       0       0   \n",
       "  40                          191       2       0       0       0       0   \n",
       "  50                          168      26       0       0       0       0   \n",
       "  60                          158      18      49      93      21      36   \n",
       "  70                           68      44      15     122      10      15   \n",
       "  80                           89      16       9      22      15     140   \n",
       "  90                            7      12     119      70       1       9   \n",
       "  100                          16       1       9     116      12      12   \n",
       "  \n",
       "                           cm_4_4  classifier  \n",
       "  perturbation_percentage                      \n",
       "  0                           200       CASIM  \n",
       "  10                          200       CASIM  \n",
       "  20                          200       CASIM  \n",
       "  30                          200       CASIM  \n",
       "  40                          200       CASIM  \n",
       "  50                          200       CASIM  \n",
       "  60                            1       CASIM  \n",
       "  70                           38       CASIM  \n",
       "  80                           14       CASIM  \n",
       "  90                            1       CASIM  \n",
       "  100                          51       CASIM  \n",
       "  \n",
       "  [11 rows x 26 columns]},\n",
       " 'EAC_1NN': {'results': fold                         0      1      2      3      4  average\n",
       "  perturbation_percentage                                            \n",
       "  0                        0.200  0.200  0.200  0.200  0.200    0.200\n",
       "  10                       0.200  0.200  0.200  0.200  0.200    0.200\n",
       "  20                       0.205  0.215  0.195  0.195  0.195    0.201\n",
       "  30                       0.205  0.210  0.190  0.185  0.190    0.196\n",
       "  40                       0.195  0.210  0.200  0.185  0.185    0.195\n",
       "  50                       0.185  0.145  0.175  0.190  0.175    0.174\n",
       "  60                       0.220  0.155  0.195  0.180  0.175    0.185\n",
       "  70                       0.235  0.170  0.190  0.225  0.200    0.204\n",
       "  80                       0.245  0.175  0.185  0.235  0.205    0.209\n",
       "  90                       0.205  0.185  0.185  0.215  0.140    0.186\n",
       "  100                      0.170  0.115  0.140  0.185  0.135    0.149,\n",
       "  'confusion_matrices':                          cm_0_0  cm_0_1  cm_0_2  cm_0_3  cm_0_4  cm_1_0  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           200       0       0       0       0     200   \n",
       "  10                          200       0       0       0       0     200   \n",
       "  20                          188      12       0       0       0     187   \n",
       "  30                          184      16       0       0       0     188   \n",
       "  40                          176      24       0       0       0     181   \n",
       "  50                           36     141       0      23       0     128   \n",
       "  60                           44     125       0      31       0     115   \n",
       "  70                           63      99       0      38       0     100   \n",
       "  80                           68      88       0      44       0      84   \n",
       "  90                           35      69       0      55      41      36   \n",
       "  100                           0      86       0      71      43       0   \n",
       "  \n",
       "                           cm_1_1  cm_1_2  cm_1_3  cm_1_4  ...  cm_3_1  cm_3_2  \\\n",
       "  perturbation_percentage                                  ...                   \n",
       "  0                             0       0       0       0  ...       0       0   \n",
       "  10                            0       0       0       0  ...       0       0   \n",
       "  20                           13       0       0       0  ...       3       0   \n",
       "  30                           12       0       0       0  ...       4       0   \n",
       "  40                           19       0       0       0  ...      10       0   \n",
       "  50                           46       0      26       0  ...      55       0   \n",
       "  60                           56       0      29       0  ...      57       0   \n",
       "  70                           69       0      31       0  ...      65       0   \n",
       "  80                           83       0      33       0  ...      80       0   \n",
       "  90                           94       0      38      32  ...      86       0   \n",
       "  100                         128       0      46      26  ...     148       0   \n",
       "  \n",
       "                           cm_3_3  cm_3_4  cm_4_0  cm_4_1  cm_4_2  cm_4_3  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                             0       0     200       0       0       0   \n",
       "  10                            0       0     200       0       0       0   \n",
       "  20                            0       0     182      18       0       0   \n",
       "  30                            0       0     183      17       0       0   \n",
       "  40                            0       0     171      29       0       0   \n",
       "  50                           92       0     102      79       0      19   \n",
       "  60                           85       0      96      84       0      20   \n",
       "  70                           72       0      85      94       0      21   \n",
       "  80                           58       0      70     100       0      30   \n",
       "  90                           37      30      39     106       0      35   \n",
       "  100                          21      31       0     153       0      47   \n",
       "  \n",
       "                           cm_4_4  classifier  \n",
       "  perturbation_percentage                      \n",
       "  0                             0     EAC_1NN  \n",
       "  10                            0     EAC_1NN  \n",
       "  20                            0     EAC_1NN  \n",
       "  30                            0     EAC_1NN  \n",
       "  40                            0     EAC_1NN  \n",
       "  50                            0     EAC_1NN  \n",
       "  60                            0     EAC_1NN  \n",
       "  70                            0     EAC_1NN  \n",
       "  80                            0     EAC_1NN  \n",
       "  90                           20     EAC_1NN  \n",
       "  100                           0     EAC_1NN  \n",
       "  \n",
       "  [11 rows x 26 columns]},\n",
       " 'MBW_LR': {'results': fold                         0      1      2      3      4  average\n",
       "  perturbation_percentage                                            \n",
       "  0                        0.970  0.995  0.980  0.985  0.985    0.983\n",
       "  10                       0.950  0.990  0.960  0.950  0.970    0.964\n",
       "  20                       0.900  0.975  0.940  0.935  0.970    0.944\n",
       "  30                       0.880  0.940  0.930  0.905  0.930    0.917\n",
       "  40                       0.905  0.900  0.835  0.900  0.905    0.889\n",
       "  50                       0.840  0.820  0.780  0.865  0.885    0.838\n",
       "  60                       0.805  0.795  0.685  0.745  0.795    0.765\n",
       "  70                       0.600  0.575  0.565  0.570  0.570    0.576\n",
       "  80                       0.280  0.165  0.205  0.170  0.165    0.197\n",
       "  90                       0.025  0.075  0.045  0.040  0.035    0.044\n",
       "  100                      0.000  0.025  0.005  0.010  0.000    0.008,\n",
       "  'confusion_matrices':                          cm_0_0  cm_0_1  cm_0_2  cm_0_3  cm_0_4  cm_1_0  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           195       0       5       0       0       0   \n",
       "  10                          196       1       1       2       0       0   \n",
       "  20                          196       0       1       3       0       3   \n",
       "  30                          189       1       3       5       2       6   \n",
       "  40                          185       0       4       7       4       8   \n",
       "  50                          175       2       6       7      10      11   \n",
       "  60                          150       2       9      18      21      20   \n",
       "  70                           90      13      17      33      47      25   \n",
       "  80                           52      29      25      49      45      45   \n",
       "  90                            9      53      39      54      45      58   \n",
       "  100                           4      45      34      87      30      59   \n",
       "  \n",
       "                           cm_1_1  cm_1_2  cm_1_3  cm_1_4  ...  cm_3_1  cm_3_2  \\\n",
       "  perturbation_percentage                                  ...                   \n",
       "  0                           197       0       3       0  ...       0       0   \n",
       "  10                          191       3       3       3  ...       0       2   \n",
       "  20                          181       5      11       0  ...       1       1   \n",
       "  30                          172       8      11       3  ...       3       2   \n",
       "  40                          163      12      12       5  ...       6       3   \n",
       "  50                          144      20      17       8  ...      12       2   \n",
       "  60                          124      27      21       8  ...      15       7   \n",
       "  70                          102      29      32      12  ...      29      22   \n",
       "  80                           41      43      45      26  ...      32      32   \n",
       "  90                           12      61      36      33  ...      44      43   \n",
       "  100                           0      69      36      36  ...      55      43   \n",
       "  \n",
       "                           cm_3_3  cm_3_4  cm_4_0  cm_4_1  cm_4_2  cm_4_3  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           200       0       0       0       0       0   \n",
       "  10                          190       0       1       0       0       0   \n",
       "  20                          191       0       9       2       0       3   \n",
       "  30                          187       0      14       3       0       4   \n",
       "  40                          175       8      15       4       0       4   \n",
       "  50                          168      10      20       5       1       3   \n",
       "  60                          152      16      22       6       3       3   \n",
       "  70                          103      26      26      24      15       7   \n",
       "  80                           45      35      66      50      28      10   \n",
       "  90                           14      39      66      72      42      15   \n",
       "  100                           4      34      51      69      46      34   \n",
       "  \n",
       "                           cm_4_4  classifier  \n",
       "  perturbation_percentage                      \n",
       "  0                           200      MBW_LR  \n",
       "  10                          199      MBW_LR  \n",
       "  20                          186      MBW_LR  \n",
       "  30                          179      MBW_LR  \n",
       "  40                          177      MBW_LR  \n",
       "  50                          171      MBW_LR  \n",
       "  60                          166      MBW_LR  \n",
       "  70                          128      MBW_LR  \n",
       "  80                           46      MBW_LR  \n",
       "  90                            5      MBW_LR  \n",
       "  100                           0      MBW_LR  \n",
       "  \n",
       "  [11 rows x 26 columns]},\n",
       " 'ACM_SVM': {'results': fold                         0      1      2      3      4  average\n",
       "  perturbation_percentage                                            \n",
       "  0                        0.920  0.870  0.935  0.925  0.935    0.917\n",
       "  10                       0.885  0.850  0.910  0.875  0.900    0.884\n",
       "  20                       0.880  0.840  0.890  0.880  0.895    0.877\n",
       "  30                       0.875  0.830  0.870  0.865  0.890    0.866\n",
       "  40                       0.870  0.825  0.870  0.860  0.870    0.859\n",
       "  50                       0.860  0.830  0.865  0.850  0.850    0.851\n",
       "  60                       0.840  0.815  0.870  0.870  0.830    0.845\n",
       "  70                       0.755  0.640  0.785  0.565  0.745    0.698\n",
       "  80                       0.150  0.030  0.160  0.170  0.130    0.128\n",
       "  90                       0.000  0.010  0.000  0.015  0.005    0.006\n",
       "  100                      0.005  0.000  0.000  0.005  0.000    0.002,\n",
       "  'confusion_matrices':                          cm_0_0  cm_0_1  cm_0_2  cm_0_3  cm_0_4  cm_1_0  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           185       3      10       2       0       0   \n",
       "  10                          178       4      16       2       0       0   \n",
       "  20                          175       6      16       3       0       0   \n",
       "  30                          169       8      20       3       0       0   \n",
       "  40                          168       8      21       3       0       0   \n",
       "  50                          168      10      16       6       0       0   \n",
       "  60                          168       7      15      10       0       0   \n",
       "  70                           62      80      36      22       0       0   \n",
       "  80                           15      90      83       5       7     197   \n",
       "  90                            5     175       0      20       0     200   \n",
       "  100                           1      11       5     180       3      45   \n",
       "  \n",
       "                           cm_1_1  cm_1_2  cm_1_3  cm_1_4  ...  cm_3_1  cm_3_2  \\\n",
       "  perturbation_percentage                                  ...                   \n",
       "  0                           198       0       2       0  ...      36       0   \n",
       "  10                          200       0       0       0  ...      58       0   \n",
       "  20                          200       0       0       0  ...      60       0   \n",
       "  30                          200       0       0       0  ...      60       0   \n",
       "  40                          200       0       0       0  ...      65       0   \n",
       "  50                          200       0       0       0  ...      63       0   \n",
       "  60                          200       0       0       0  ...      53       0   \n",
       "  70                          200       0       0       0  ...      63       0   \n",
       "  80                            3       0       0       0  ...      59      13   \n",
       "  90                            0       0       0       0  ...      27       2   \n",
       "  100                           0     154       0       1  ...      21      50   \n",
       "  \n",
       "                           cm_3_3  cm_3_4  cm_4_0  cm_4_1  cm_4_2  cm_4_3  \\\n",
       "  perturbation_percentage                                                   \n",
       "  0                           164       0       0      24       0       0   \n",
       "  10                          142       0       0      33       0       0   \n",
       "  20                          140       0       0      35       0       0   \n",
       "  30                          140       0       0      39       0       0   \n",
       "  40                          135       0       0      40       0       0   \n",
       "  50                          137       0       0      44       0       0   \n",
       "  60                          147       0       0      43       0       0   \n",
       "  70                          136       1       0      57       0       1   \n",
       "  80                            2       0      71      25      43      60   \n",
       "  90                            0       0     101      55      44       0   \n",
       "  100                           0      18      63      71      65       1   \n",
       "  \n",
       "                           cm_4_4  classifier  \n",
       "  perturbation_percentage                      \n",
       "  0                           176     ACM_SVM  \n",
       "  10                          167     ACM_SVM  \n",
       "  20                          165     ACM_SVM  \n",
       "  30                          161     ACM_SVM  \n",
       "  40                          160     ACM_SVM  \n",
       "  50                          156     ACM_SVM  \n",
       "  60                          157     ACM_SVM  \n",
       "  70                          142     ACM_SVM  \n",
       "  80                            1     ACM_SVM  \n",
       "  90                            0     ACM_SVM  \n",
       "  100                           0     ACM_SVM  \n",
       "  \n",
       "  [11 rows x 26 columns]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturber = LabelPerturber(random_state=RANDOM_SEED)\n",
    "robustness_tester = RobustnessTester(\n",
    "    classifiers_dict=CLASSIFIERS,\n",
    "    perturber=perturber,\n",
    "    n_splits=N_SPLITS,\n",
    "    perturbation_step_size=PERTURBATION_STEP_SIZE,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "robustness_tester.test_all_classifiers(X, y, perturbation_steps=10, save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9088b",
   "metadata": {},
   "source": [
    "### Fluidized Catalytic Cracking (FCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7810c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset_from_folder(\"data/fcc\", MAX_DATA_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
